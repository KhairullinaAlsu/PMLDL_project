{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load data\n",
        "tracks_df = pd.read_csv('cleaned_tracks_dataset.csv')\n",
        "user_tracks_df = pd.read_csv('users_tracks_cleaned.csv', usecols=range(11))\n",
        "\n",
        "# Get unique tracks\n",
        "unique_tracks = tracks_df['track_id'].unique()\n",
        "\n",
        "# Initialize user-track interaction matrix\n",
        "user_track_matrix = pd.DataFrame(0, index=user_tracks_df['user_id'], columns=unique_tracks)\n",
        "\n",
        "# Populate the user-track matrix with user preferences\n",
        "for index, row in user_tracks_df.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    for track_id in row[1:]:\n",
        "        user_track_matrix.loc[user_id, track_id] = 1\n",
        "\n",
        "# Fit the NMF model\n",
        "nmf_model = NMF(n_components=10, init='nndsvd', random_state=42, max_iter=500)\n",
        "user_factors = nmf_model.fit_transform(user_track_matrix)\n",
        "track_factors = nmf_model.components_\n",
        "\n",
        "# Generate predictions\n",
        "predictions = {}\n",
        "\n",
        "for user_id in tqdm(user_track_matrix.index, desc=\"Generating recommendations\"):\n",
        "    # Get the index of the user in the user_factors array\n",
        "    user_index = user_track_matrix.index.get_loc(user_id)\n",
        "\n",
        "    # Calculate the user's preference scores for all tracks\n",
        "    user_preferences = np.dot(user_factors[user_index], track_factors)\n",
        "\n",
        "    # Get the user's favorite tracks to exclude them from recommendations\n",
        "    user_fav_tracks = user_tracks_df[user_tracks_df['user_id'] == user_id].values[0][1:]\n",
        "    user_fav_tracks = set(filter(pd.notnull, user_fav_tracks))\n",
        "\n",
        "    # Create a list of tracks the user hasn't listened to, along with their predicted scores\n",
        "    recommendations = [\n",
        "        (track, score)\n",
        "        for track, score in zip(user_track_matrix.columns, user_preferences)\n",
        "        if track not in user_fav_tracks\n",
        "    ]\n",
        "\n",
        "    # Sort the recommendations by predicted score in descending order\n",
        "    top_recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "    # Store the top 20 recommended track IDs for the user\n",
        "    predictions[user_id] = [track for track, score in top_recommendations]\n",
        "\n",
        "# Convert the predictions dictionary to a DataFrame\n",
        "predictions_df = pd.DataFrame.from_dict(predictions, orient='index')\n",
        "\n",
        "# Set the column names for the recommendations\n",
        "predictions_df.columns = [f'rec_{i+1}' for i in range(predictions_df.shape[1])]\n",
        "\n",
        "# Save the recommendations to a CSV file\n",
        "predictions_df.to_csv('user_recommendations_NMF.csv', index_label='user')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3lY1NByCbGJ",
        "outputId": "9b63028f-fea0-483d-8821-2a702592fcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating recommendations: 100%|██████████| 8792/8792 [02:29<00:00, 58.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('cleaned_tracks_dataset.csv')\n",
        "\n",
        "# Define the features to be used (excluding categorical features)\n",
        "features = [\n",
        "    'track_popularity', 'danceability', 'energy', 'key', 'loudness',\n",
        "    'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
        "    'liveness', 'valence', 'tempo', 'duration_ms'\n",
        "]\n",
        "\n",
        "# Ensure 'track_id' is included in the DataFrame\n",
        "required_columns = ['track_id'] + features\n",
        "df = df[required_columns]\n",
        "\n",
        "# Convert 'track_id' to string to ensure consistency\n",
        "df['track_id'] = df['track_id'].astype(str)\n",
        "\n",
        "# Prepare the feature matrix\n",
        "X = df[features]\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize and fit the KNN model with a higher number of neighbors\n",
        "knn = NearestNeighbors(n_neighbors=50, metric='cosine')\n",
        "knn.fit(X_scaled)\n",
        "\n",
        "# Function to recommend songs for a single user\n",
        "def recommend_songs(user_fav_tracks, df, knn_model, scaler):\n",
        "    # Ensure track IDs are strings\n",
        "    user_fav_tracks = [str(track_id) for track_id in user_fav_tracks if pd.notnull(track_id)]\n",
        "\n",
        "    # Get features of the user's favorite tracks\n",
        "    fav_tracks_features = df[df['track_id'].isin(user_fav_tracks)][features]\n",
        "\n",
        "    if fav_tracks_features.empty:\n",
        "        # If favorite tracks are not in the dataset, return a list of None\n",
        "        return [None] * 20\n",
        "\n",
        "    # Scale the features of favorite tracks\n",
        "    fav_tracks_scaled = scaler.transform(fav_tracks_features)\n",
        "\n",
        "    # Find nearest neighbors\n",
        "    distances, indices = knn_model.kneighbors(fav_tracks_scaled)\n",
        "\n",
        "    # Collect recommended track IDs\n",
        "    recommended_songs = []\n",
        "    for idx in indices:\n",
        "        recommended_songs.extend(df.iloc[idx]['track_id'].values)\n",
        "\n",
        "    # Remove duplicates and already liked tracks\n",
        "    recommended_songs = np.unique(recommended_songs)\n",
        "    recommended_songs = [song for song in recommended_songs if song not in user_fav_tracks]\n",
        "\n",
        "    # Ensure the list has exactly 20 recommendations\n",
        "    recommendations_padded = recommended_songs[:20]\n",
        "    recommendations_padded += [None] * (20 - len(recommendations_padded))\n",
        "\n",
        "    return recommendations_padded\n",
        "\n",
        "# Load user favorite tracks\n",
        "user_tracks_df = pd.read_csv('users_tracks_cleaned.csv', usecols=range(11))\n",
        "\n",
        "# Function to recommend songs for all users\n",
        "def recommend_for_all_users(user_tracks_df, df, knn_model, scaler):\n",
        "    predictions = {}\n",
        "\n",
        "    # Iterate over each user with a progress bar\n",
        "    for index, row in tqdm(user_tracks_df.iterrows(), total=user_tracks_df.shape[0], desc=\"Generating recommendations\"):\n",
        "        user_id = row['user_id']\n",
        "        # Get the user's favorite tracks, ensuring they are strings\n",
        "        user_fav_tracks = row[1:].astype(str).values\n",
        "        recommended_songs = recommend_songs(user_fav_tracks, df, knn_model, scaler)\n",
        "        predictions[user_id] = recommended_songs\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Generate recommendations for all users\n",
        "predictions = recommend_for_all_users(user_tracks_df, df, knn, scaler)\n",
        "\n",
        "# Create a DataFrame from the predictions dictionary\n",
        "columns = [f'rec_{i+1}' for i in range(20)]\n",
        "predictions_df = pd.DataFrame.from_dict(predictions, orient='index', columns=columns)\n",
        "\n",
        "# Save the recommendations to a CSV file\n",
        "predictions_df.to_csv('user_recommendations_KNN.csv', index_label='user')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEezomFXHjzf",
        "outputId": "c61e7350-9f65-4df2-a4f6-520a16a32c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating recommendations: 100%|██████████| 8792/8792 [02:27<00:00, 59.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the datasets\n",
        "cleaned_tracks_dataset = pd.read_csv('cleaned_tracks_dataset.csv')\n",
        "user_tracks_cleaned = pd.read_csv('users_tracks_cleaned.csv', usecols=range(11))\n",
        "\n",
        "# Define the features to be used\n",
        "features = [\n",
        "    'artistname', 'track_popularity', 'playlist_genre', 'playlist_subgenre',\n",
        "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
        "    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms'\n",
        "]\n",
        "\n",
        "# Prepare track features DataFrame\n",
        "track_features = cleaned_tracks_dataset[features]\n",
        "track_features = track_features.set_index(cleaned_tracks_dataset['track_id'])\n",
        "\n",
        "# Convert track IDs to strings to ensure consistency\n",
        "track_features.index = track_features.index.astype(str)\n",
        "\n",
        "# Initialize the graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Get unique user and track IDs\n",
        "user_ids = user_tracks_cleaned['user_id'].unique()\n",
        "track_ids = cleaned_tracks_dataset['track_id'].unique()\n",
        "track_ids = track_ids.astype(str)  # Ensure track IDs are strings\n",
        "\n",
        "# Add user and track nodes to the graph\n",
        "for user_id in user_ids:\n",
        "    G.add_node(user_id, type='user')\n",
        "\n",
        "for track_id in track_ids:\n",
        "    G.add_node(track_id, type='track')\n",
        "\n",
        "# Add edges between users and their favorite tracks\n",
        "for _, row in user_tracks_cleaned.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    # Convert track IDs to strings and filter out NaN values\n",
        "    favorite_tracks = row[1:].dropna().astype(str).tolist()\n",
        "    for track_id in favorite_tracks:\n",
        "        G.add_edge(user_id, track_id)\n",
        "\n",
        "# Define the recommendation function\n",
        "def recommend(user_id, G, track_features, top_n=20):\n",
        "    neighbors = list(G.neighbors(user_id))\n",
        "\n",
        "    if not neighbors:\n",
        "        return []\n",
        "\n",
        "    listened_tracks = [n for n in neighbors if G.nodes[n]['type'] == 'track']\n",
        "    listened_features = track_features.loc[listened_tracks].values\n",
        "\n",
        "    # Handle case where listened_features is empty\n",
        "    if listened_features.size == 0:\n",
        "        return []\n",
        "\n",
        "    avg_features = np.mean(listened_features, axis=0)\n",
        "\n",
        "    # Compute cosine similarity between the average features and all tracks\n",
        "    similarity_scores = cosine_similarity([avg_features], track_features.values)[0]\n",
        "\n",
        "    # Get indices of tracks sorted by similarity score in descending order\n",
        "    sorted_indices = np.argsort(similarity_scores)[::-1]\n",
        "\n",
        "    recommended_tracks = []\n",
        "    for idx in sorted_indices:\n",
        "        track_id = track_features.index[idx]\n",
        "        if track_id not in listened_tracks:\n",
        "            recommended_tracks.append(track_id)\n",
        "        if len(recommended_tracks) >= top_n:\n",
        "            break\n",
        "\n",
        "    return recommended_tracks\n",
        "\n",
        "# Prepare the columns for recommendations\n",
        "recommendation_columns = [f'rec_{i+1}' for i in range(20)]\n",
        "user_recommendations_GNN = pd.DataFrame(columns=['user'] + recommendation_columns)\n",
        "\n",
        "# Generate recommendations for each user with a progress bar\n",
        "for user_id in tqdm(user_ids, desc=\"Generating recommendations\"):\n",
        "    recommendations = recommend(user_id, G, track_features)\n",
        "    rec_dict = {'user': user_id}\n",
        "    for i in range(20):\n",
        "        rec_key = f'rec_{i+1}'\n",
        "        rec_dict[rec_key] = recommendations[i] if i < len(recommendations) else None\n",
        "    new_row = pd.DataFrame(rec_dict, index=[0])\n",
        "    user_recommendations_GNN = pd.concat([user_recommendations_GNN, new_row], ignore_index=True)\n",
        "\n",
        "# Save the recommendations to a CSV file\n",
        "user_recommendations_GNN.to_csv('user_recommendations_GNN.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67szEnvYP4Fc",
        "outputId": "cb09a1e1-c29b-4719-fd3c-3c0e0376aa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating recommendations: 100%|██████████| 8792/8792 [01:09<00:00, 127.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the LightFM library if it's not already installed (uncomment if needed)\n",
        "# !pip install lightfm\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k\n",
        "\n",
        "# Load the datasets for tracks and user interactions\n",
        "tracks_df = pd.read_csv('cleaned_tracks_dataset.csv')  # Dataset containing track information\n",
        "users_df = pd.read_csv('users_tracks_cleaned.csv')     # Dataset containing user-track interactions\n",
        "\n",
        "# Set the number of recommendations to generate for each user\n",
        "num_recommendations = 20\n",
        "\n",
        "# Create a Dataset object for preparing data for the LightFM model\n",
        "dataset = Dataset()\n",
        "\n",
        "# Fit the dataset with unique user and track IDs\n",
        "dataset.fit(\n",
        "    users_df['user_id'].unique(),   # Unique user IDs\n",
        "    tracks_df['track_id'].unique()  # Unique track IDs\n",
        ")\n",
        "\n",
        "# Select track features to be used in the model\n",
        "track_features = tracks_df[['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
        "                            'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
        "                            'valence', 'tempo', 'duration_ms']]\n",
        "\n",
        "# Set 'track_id' as the index for the features dataframe\n",
        "track_features = track_features.set_index('track_id')\n",
        "\n",
        "# Binarize track features based on their median values\n",
        "track_features_binary = track_features.apply(lambda x: (x > x.median()).astype(int))\n",
        "\n",
        "# Update the dataset with item (track) features\n",
        "dataset.fit_partial(\n",
        "    items=track_features_binary.index,          # Track IDs\n",
        "    item_features=track_features_binary.columns # Feature names\n",
        ")\n",
        "\n",
        "# Build the interaction matrix between users and tracks\n",
        "interactions, weights = dataset.build_interactions([\n",
        "    (row['user_id'], track_id)                   # (user ID, track ID) pairs\n",
        "    for _, row in users_df.iterrows()            # Iterate over each row in the users dataframe\n",
        "    for track_id in row[1:11].values             # Take the first 10 track IDs for each user\n",
        "])\n",
        "\n",
        "# Build the item (track) features matrix\n",
        "track_features_matrix = dataset.build_item_features([\n",
        "    (track_id, track_features_binary.loc[track_id].values)  # (track ID, binary features)\n",
        "    for track_id in track_features_binary.index             # Iterate over all track IDs\n",
        "])\n",
        "\n",
        "# Initialize the LightFM model with the 'warp' loss function\n",
        "model = LightFM(loss='warp')\n",
        "\n",
        "# Train the model using the interaction matrix and track features\n",
        "model.fit(\n",
        "    interactions,                    # User-track interaction matrix\n",
        "    item_features=track_features_matrix, # Track features matrix\n",
        "    epochs=30                        # Number of training epochs\n",
        ")\n",
        "\n",
        "# Define a function to get recommendations for a given user\n",
        "def get_recommendations(user_id, top_n=num_recommendations):\n",
        "    # Find the index of the user in the users dataframe\n",
        "    user_index = np.where(users_df['user_id'] == user_id)[0][0]\n",
        "    # Predict scores for all tracks for the given user\n",
        "    scores = model.predict(\n",
        "        [user_index] * len(tracks_df),         # Repeat user index for all tracks\n",
        "        np.arange(len(tracks_df)),             # Indices of all tracks\n",
        "        item_features=track_features_matrix    # Track features matrix\n",
        "    )\n",
        "    # Get the indices of the top-N tracks with the highest scores\n",
        "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
        "    # Retrieve the track IDs of the recommended tracks\n",
        "    recommended_tracks = tracks_df.iloc[top_indices]['track_id'].values\n",
        "    return recommended_tracks\n",
        "\n",
        "# Create a list of column names for the recommendations\n",
        "recommendation_columns = ['rec_{}'.format(i) for i in range(1, num_recommendations + 1)]\n",
        "\n",
        "# Initialize an empty DataFrame to store the recommendations\n",
        "recommendations_df = pd.DataFrame(columns=['user'] + recommendation_columns)\n",
        "\n",
        "# List to accumulate recommendation dictionaries\n",
        "recommendations_list = []\n",
        "\n",
        "# Generate recommendations for each user\n",
        "for user_id in users_df['user_id'].unique():\n",
        "    # Get recommendations for the current user\n",
        "    rec_tracks = get_recommendations(user_id)\n",
        "    # Create a dictionary to store the user's recommendations\n",
        "    rec_dict = {'user': user_id}\n",
        "    for i in range(num_recommendations):\n",
        "        rec_dict['rec_{}'.format(i + 1)] = rec_tracks[i]\n",
        "    # Add the dictionary to the recommendations list\n",
        "    recommendations_list.append(rec_dict)\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "recommendations_df = pd.DataFrame(recommendations_list)\n",
        "\n",
        "# Save the recommendations DataFrame to a CSV file\n",
        "recommendations_df.to_csv('user_recommendations_LightFM.csv', index=False)"
      ],
      "metadata": {
        "id": "dCwDteNGSzoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}